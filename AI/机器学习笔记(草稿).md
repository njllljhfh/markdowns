# 一、数学基础1-数学分析

 概率（测度？）

sigmoid函数，Logistic函数

概率密度函数（Probability Density Function)，简称PDF

累计分布函数（Cumulative Distribution Function），简称CDF

古典概型

信息熵

贝叶斯学派 和 频率学派

泊松分布、二项分布、两点分布。（都是离散的）

均匀分布、指数分布、正态分布、二元正态分布

泰勒展开式

指数族分布：泊松分布、二项分布、两点分布、高斯分布



---



数据收集 → 数据清洗 → 特征工程 → 数据建模

特征决定模型的的上限（理解业务）

LDA：线性判别分析



`加速度` 的方向总是指向轨迹曲线凹的一侧。



O(lnN!)  约等于 O(NlnN)

## Sigmoid/Logistic函数

$$
f(x) = \cfrac{1}{1+e^{-x}}
$$



## 二、数学基础2-数理统计与参数估计

- 期望（均值）
- 方差
- 标准差
- 协方差

- 所谓的X、Y`不相关`，是一维上的，X、Y没有`线性相关`性，协方差=0，Pearson相关系数=0

- X、Y独立，则X、Y一定不相关，反之不一定成立。

- 协方差矩阵，是对称矩阵
- 正交矩阵
- X的k阶原点矩：$E(X^{k})$，X的`1阶原点矩`就是`期望`
- X的k阶中心距： $E\{[X-E(X)]^{k}\}​$，X的`2阶中心距`就是`方差`

- 变异系数：`标准差`与`期望`的比值称为`变异系数`，记为CV
- 偏度
- 超值峰度
- 峰度x
- 切比雪夫不等式
- 大数定理
- 中心极限定理
- k阶样本原点矩
- k阶样本中心距
- 样本方差
- 矩估计：用样本去估计总体

- 最大似然估计
- 对数似然函数

- 矩估计和最大似然估计的思想不一样，但是结论是一样的。
- 偏差
- 欠拟合
- 过拟合



## 三、数学基础3-矩阵和线性代数

- 范德蒙行列式
- 插值（自己找教材看）
- 保证样本点距离拟合曲线不是太远
- （条件）概率转移矩阵
- 全概率公式
- 特征值
- 特征向量（特征向量一定是非零的）
- 一个 `m×n的矩阵A` 乘以 一个 `n维列向量x` 得到一个 `m维的列向量`，实际上是将一个n维空间上的一个点x 通过矩阵A 映射成了一个m维空间上的点y。如果m=n则是在同一个维度空间中的映射。
- 分治算法、动态规划（自己去了解）
- 向量组等价
- 系数矩阵
- 线性表出
- 正交阵，正交变换（正交变换不改变向量长度）
- 矩阵的迹
- 对称阵
- 对角化，合同变换
- 白化/漂白whitening（经过该预处理后，再经过其他处理，最后的结果不一定会理想，有可能还不如不白化）
- 中心化
- 正定阵，半正定阵，负定阵，半负定阵（`正定`，其实就 是`正数` 在 `n维` 上的推广）。正定阵的特征值都为正数
- 向量对向量求导
- 超越矩阵 
- 行列式等于0的方阵是奇异矩阵，不等于0是非奇异矩阵
- QR分解（计算n阶方阵的特征值）
- 隐特征，LFM



## 四、数学基础4-凸优化

### 4.1、凸集

- 凸函数
- 凸集：
  - 定义：集合C内任意两点间的线段均在集合C内，则称集合C为 `凸集`
  - 凸函数 图像 上方的区域，一定是 凸集
- 拐点：求出二阶导数等于零，和二阶导数不存在的点。那么当改点两侧的符号相反时，改点是拐点；改点两侧符号相同时不是拐点。
- 仿射集（Affine set）
  - 定义：通过集合C中的任意两个不同点的直线仍然在集合C内，则称集合C为 `仿射集`。
  - 仿射集一定是无界的
  - 仿射集的例子：直线、平面、超平面
  - n维空间的n-1维仿射集为n-1维超平面。
  - 如果一个集合是仿射集，那么它一定是凸集
- 凸包：
  - 定义：集合C的所有点的凸组合形成的集合，叫做集合C的凸包。
- 超平面、半空间
- 二范式（点乘后开平方）
- 范数
- 绝对值：其实就是 一范式
- 范数球
- 范数锥
- 多面体：
  - 仿射集、射线、线段、半空间都是多面体
- 保持凸性的运算
  - 集合交运算
  - 仿射变换
    - 伸缩
    - 平移
    - 投影
  - 透视变换
  - 投射变换
    - 投射函数是透视函数和仿射函数的复合
- 分割超平面 
- 支撑超平面
  - 凸集边界上任意一点，均存在支撑超平面。
- Hessian矩阵（多元函数的二阶导的矩阵）
- 上境图、逐点上确界
- 亚图
- Jensen不等式（是几乎所有不等式的基础）
- 共轭函数
- Fenchel不等式
- Lagrange函数
- Lagrange对偶函数（一定是凹函数）
- KKT条件





# 六、

- 时域
- 频域
- 快速傅里叶变换FFT
- 奇异值分解(SVD)、SVD++。可做推荐系统
  - ALS
- 卷积



# 七、回归

- 样本的预测值是连续的称为回归(如：商品价格)
- 样本的预测值是离散的称为分类(如：投硬币)

- 线性回归：
  - 高斯分布
  - 最大似然估计MLE
  - 最小二乘法

- Logistic回归
  - 分类问题的首选算法
- 实践中，有时候并不是特征越多，结果越好
- Lasso
- Ridge(岭回归，L2正则化)
- GridSearchCV(CV：交叉验证)

- 最小二乘法(样本服从高斯分布。样本的预测值与真实值的误差服从高斯分布$N(0, \sigma^2)$ )
  - 实际问题中，可能并不服从高斯分布，但是在机器学习中经常假定问题近似服从高斯分布。

- 广义逆矩阵(伪逆)
- 梯度下降算法

- 随机梯度下降(SGD)
  - 很常用的是mini-batch的随机梯度下降算法
  - 速度快